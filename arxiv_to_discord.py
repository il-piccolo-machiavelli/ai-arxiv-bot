import feedparser
import requests
import os
from datetime import datetime, timedelta

ARXIV_URL = (
    "http://export.arxiv.org/api/query?search_query="
    "(cat:cs.CV+OR+cat:cs.GR+OR+cat:eess.IV)"
    "&sortBy=submittedDate&max_results=60"
)

KEYWORDS_2D = [
    "text-to-image", "image-to-image", "diffusion", "latent diffusion",
    "gan", "vae", "autoregressive", "normalizing flow", "energy-based"
]

KEYWORDS_3D = [
    "text-to-3d", "image-to-3d", "3d reconstruction", "point cloud", "mesh",
    "polygon mesh", "solid", "solid modeling", "nerf", "3dgs", "sdf", "stylesdf",
    "deepcad", "3d-gpt", "csg", "csgnet", "occupancy network",
    "latent point diffusion model", "meshgpt", "point-e", "get3d", "atlasnet", "cad agent"
]

WEBHOOK_2D = os.environ["WEBHOOK_2D"]
WEBHOOK_3D = os.environ["WEBHOOK_3D"]

# ì£¼ë§ê³¼ í‰ì¼ì„ ê³ ë ¤í•œ ë‚ ì§œ ê¸°ì¤€ ì„¤ì •
today_weekday = datetime.utcnow().weekday()
if today_weekday == 0:  # ì›”ìš”ì¼
    days_ago = 3  # ê¸ˆìš”ì¼ ë…¼ë¬¸ê¹Œì§€ í¬í•¨
elif today_weekday == 1:  # í™”ìš”ì¼
    days_ago = 4  # ê¸ˆìš”ì¼ ë…¼ë¬¸ê¹Œì§€ í¬í•¨
else:
    days_ago = 1  # ì–´ì œ ë…¼ë¬¸ë§Œ

date_threshold = datetime.utcnow() - timedelta(days=days_ago)
feed = feedparser.parse(ARXIV_URL)

def send_to_discord(webhook_url, content):
    requests.post(webhook_url, json={"content": content})
    response = requests.post(webhook_url, json={"content": content})
    print(f"ğŸ“¤ Discord ì „ì†¡ ì‘ë‹µ: {response.status_code}")
    if response.status_code != 204:
        print(f"â— ì‘ë‹µ ë³¸ë¬¸: {response.text}")

def contains_keyword(text, keywords):
    clean_text = text.replace("-", "").replace("\n", "").replace(" ", "")
    return any(kw.replace(" ", "") in clean_text for kw in keywords)

print(f"ğŸ§ª Webhook 2D ì¡´ì¬ ì—¬ë¶€: {'WEBHOOK_2D' in os.environ}")
print(f"ğŸ“¡ Webhook 2D ê¸¸ì´: {len(os.environ.get('WEBHOOK_2D', ''))}")

def filter_and_post():
    msg_2d, msg_3d = [], []

    print(f"âœ… arXivì—ì„œ ë°›ì€ ë…¼ë¬¸ ìˆ˜: {len(feed.entries)}ê°œ")
    
    # ë‚ ì§œ ë¹„êµ ì •ë³´ ì¶œë ¥
    print(f"\nğŸ—“ï¸ ê¸°ì¤€ ë‚ ì§œ (UTC): {date_threshold}")
    print(f"ğŸ•’ í˜„ì¬ ì‹œê°„ (UTC): {datetime.utcnow()}")
    print(f"ğŸ“… ìš”ì¼ ê¸°ì¤€: {['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼'][today_weekday]}ìš”ì¼, {days_ago}ì¼ ì „ ë…¼ë¬¸ê¹Œì§€ í¬í•¨")
    
    print("\nğŸ“„ ìˆ˜ì§‘ëœ ë…¼ë¬¸ ì œëª© ë° ë‚ ì§œ ëª©ë¡:")
    
    for i, entry in enumerate(feed.entries):
        title = entry.title.strip()
        updated = datetime.strptime(entry.updated, "%Y-%m-%dT%H:%M:%SZ")
        
        # ë‚ ì§œ ì •ë³´ ì¶œë ¥
        print(f" {i+1}. [{updated.strftime('%Y-%m-%d %H:%M')}] {title}")
        
        if updated < date_threshold:
            print(f"   â­ï¸ SKIP: ë‚ ì§œê°€ ê¸°ì¤€ë³´ë‹¤ ì´ì „ì„ ({updated} < {date_threshold})")
            continue
        else:
            print(f"   âœ… PASS: ë‚ ì§œ ì¡°ê±´ í†µê³¼ ({updated} >= {date_threshold})")

        text = (entry.title + " " + entry.summary).lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ë””ë²„ê¹…
        if contains_keyword(text, KEYWORDS_2D):
            print(f"   ğŸ‘‰ [2D ë§¤ì¹­ë¨] {entry.title.strip()}")
            msg_2d.append(f"ğŸ”¹ **{entry.title.strip()}**\n{entry.link}")
        
        if contains_keyword(text, KEYWORDS_3D):
            print(f"   ğŸ‘‰ [3D ë§¤ì¹­ë¨] {entry.title.strip()}")
            msg_3d.append(f"ğŸ”¸ **{entry.title.strip()}**\n{entry.link}")

    print(f"\nğŸ“Š í•„í„°ë§ ê²°ê³¼:")
    print(f"- 2D ë…¼ë¬¸: {len(msg_2d)}ê°œ")
    print(f"- 3D ë…¼ë¬¸: {len(msg_3d)}ê°œ")

    if msg_2d:
        send_to_discord(WEBHOOK_2D, "**ğŸ“¡ ì˜¤ëŠ˜ì˜ 2D ìƒì„± ë…¼ë¬¸ (arXiv)**\n\n" + "\n\n".join(msg_2d[:5]))
    else:
        print("âŒ 2D ë…¼ë¬¸ì´ ì—†ì–´ Discord ì „ì†¡ì„ ìƒëµí•©ë‹ˆë‹¤.")
    
    if msg_3d:
        send_to_discord(WEBHOOK_3D, "**ğŸ§± ì˜¤ëŠ˜ì˜ 3D ìƒì„± ë…¼ë¬¸ (arXiv)**\n\n" + "\n\n".join(msg_3d[:5]))
    else:
        print("âŒ 3D ë…¼ë¬¸ì´ ì—†ì–´ Discord ì „ì†¡ì„ ìƒëµí•©ë‹ˆë‹¤.")

filter_and_post()
